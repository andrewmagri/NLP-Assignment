Index: NaiveBayes.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from sklearn.naive_bayes import MultinomialNB\r\nfrom WordEmbeddings import *\r\nfrom Preprocessing import *\r\nfrom Tweets import *\r\nfrom sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score\r\n\r\nimport pickle\r\nimport numpy as np\r\n\r\n\r\ndef check_if_created(filename):\r\n    try:\r\n        file = open(filename + \".pickle\")\r\n        file.close()\r\n        return True\r\n    except IOError:\r\n        print(\"File not found\")\r\n        return False\r\n\r\n\r\ndef get_data(dirText, dirLabel,output_file_name):\r\n    # Obtaining tweet text\r\n    with open(dirText, \"r\",\r\n              encoding=\"utf8\") as t:\r\n        tweets = t.read()\r\n        tweets = tweets.split(\"\\n\")\r\n\r\n    # Obtaining tweet label\r\n    with open(dirLabel, \"r\",\r\n              encoding=\"utf8\") as l:\r\n        labels = l.read()\r\n        labels = labels.split(\"\\n\")\r\n\r\n    tweets_object = preprocess(tweets, labels)\r\n\r\n    with open(output_file_name+'.pickle', 'wb') as handle:\r\n        pickle.dump(tweets_object, handle, protocol=pickle.HIGHEST_PROTOCOL)\r\n\r\n    return tweets_object\r\n\r\n\r\ndef get_train_data(dirTrainText, dirTrainLabel):\r\n    filename = \"TrainTweets\"\r\n    if check_if_created(filename):\r\n        with open(filename + '.pickle', 'rb') as handle:\r\n            return pickle.load(handle)\r\n    else:\r\n        return get_data(dirTrainText, dirTrainLabel,filename)\r\n\r\n\r\ndef get_test_data(dirTestText, dirTestLabel):\r\n    filename = \"TestTweets\"\r\n    if check_if_created(filename):\r\n        with open(filename + '.pickle', 'rb') as handle:\r\n            return pickle.load(handle)\r\n    else:\r\n        return get_data(dirTestText, dirTestLabel, filename)\r\n\r\n\r\ndef preprocess(tweets,labels):\r\n    tweets_object = Tweets()\r\n    for i in range(0, len(tweets)):\r\n        tweets[i] = \" \".join(tweets[i].split())\r\n        tweets[i] = tokenize(tweets[i])\r\n\r\n        newText = []\r\n        for word in tweets[i]:\r\n            # Checking for @ Location and eliminating any words that follow\r\n            if word == \"@\":\r\n                break\r\n\r\n            word = lemmatise(word)\r\n            word = remove_stopwords(word)\r\n            word = remove_url(word)\r\n            word = remove_puncuation(word)\r\n\r\n            if word != \"\" and word is not None:\r\n                newText.append(word)\r\n\r\n        if len(newText) == 0:\r\n            continue\r\n\r\n        tweets_object.tweetsText.append(' '.join(newText))\r\n        tweets_object.tweetsLabel.append(labels[i])\r\n    return tweets_object\r\n\r\n\r\ndef naive_bayes_classifier(tfidf_matrix, labels):\r\n    nb_classifier = MultinomialNB()\r\n    nb_classifier.fit(tfidf_matrix, labels)\r\n    return nb_classifier\r\n\r\n\r\ndef run():\r\n    print()\r\n\r\n\r\ntrainTextDir =\"Semeval2018-Task2-EmojiPrediction\\\\Data\\\\tweet_by_ID_04_2_2021__05_27_42.txt.text\"\r\ntrainLabelDir = \"Semeval2018-Task2-EmojiPrediction\\\\Data\\\\tweet_by_ID_04_2_2021__05_27_42.txt.labels\"\r\ntestTextDir = \"Semeval2018-Task2-EmojiPrediction\\\\test\\\\us_test.text\"\r\ntestLabelDir = \"Semeval2018-Task2-EmojiPrediction\\\\test\\\\us_test.labels\"\r\ntrainTweets = get_train_data(trainTextDir, trainLabelDir)\r\ntestTweets = get_test_data(testTextDir, testLabelDir)\r\ntfidf_featuriser = extract_tfidf_featuriser(trainTweets.tweetsText)\r\ntrain_tfidif_matrix = tfidf_featuriser.transform(trainTweets.tweetsText)\r\ntest_tfidif_matrix = tfidf_featuriser.transform(testTweets.tweetsText)\r\nclf = naive_bayes_classifier(train_tfidif_matrix, trainTweets.tweetsLabel)\r\npredictions = clf.predict(test_tfidif_matrix)\r\nprint(predictions)\r\nprint(confusion_matrix(testTweets.tweetsLabel,predictions))\r\nprint(\"Precision: \" + str(precision_score(testTweets.tweetsLabel,predictions,average=\"macro\")))\r\nprint(\"Recall: \" + str(recall_score(testTweets.tweetsLabel,predictions,average=\"macro\")))\r\nprint(\"F1 Score: \" + str(f1_score(testTweets.tweetsLabel,predictions,average=\"macro\")))\r\naccuracy = np.sum(predictions == testTweets.tweetsLabel)/len(testTweets.tweetsLabel)\r\nprint('Accuracy: {:.3%}'.format(accuracy))\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/NaiveBayes.py b/NaiveBayes.py
--- a/NaiveBayes.py	(revision ab79391eab251b0fefd0d741390dba74ea2ba067)
+++ b/NaiveBayes.py	(date 1613843028665)
@@ -1,88 +1,7 @@
 from sklearn.naive_bayes import MultinomialNB
 from WordEmbeddings import *
-from Preprocessing import *
-from Tweets import *
-from sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score
-
-import pickle
-import numpy as np
-
-
-def check_if_created(filename):
-    try:
-        file = open(filename + ".pickle")
-        file.close()
-        return True
-    except IOError:
-        print("File not found")
-        return False
-
-
-def get_data(dirText, dirLabel,output_file_name):
-    # Obtaining tweet text
-    with open(dirText, "r",
-              encoding="utf8") as t:
-        tweets = t.read()
-        tweets = tweets.split("\n")
-
-    # Obtaining tweet label
-    with open(dirLabel, "r",
-              encoding="utf8") as l:
-        labels = l.read()
-        labels = labels.split("\n")
-
-    tweets_object = preprocess(tweets, labels)
-
-    with open(output_file_name+'.pickle', 'wb') as handle:
-        pickle.dump(tweets_object, handle, protocol=pickle.HIGHEST_PROTOCOL)
-
-    return tweets_object
-
-
-def get_train_data(dirTrainText, dirTrainLabel):
-    filename = "TrainTweets"
-    if check_if_created(filename):
-        with open(filename + '.pickle', 'rb') as handle:
-            return pickle.load(handle)
-    else:
-        return get_data(dirTrainText, dirTrainLabel,filename)
-
-
-def get_test_data(dirTestText, dirTestLabel):
-    filename = "TestTweets"
-    if check_if_created(filename):
-        with open(filename + '.pickle', 'rb') as handle:
-            return pickle.load(handle)
-    else:
-        return get_data(dirTestText, dirTestLabel, filename)
-
-
-def preprocess(tweets,labels):
-    tweets_object = Tweets()
-    for i in range(0, len(tweets)):
-        tweets[i] = " ".join(tweets[i].split())
-        tweets[i] = tokenize(tweets[i])
-
-        newText = []
-        for word in tweets[i]:
-            # Checking for @ Location and eliminating any words that follow
-            if word == "@":
-                break
-
-            word = lemmatise(word)
-            word = remove_stopwords(word)
-            word = remove_url(word)
-            word = remove_puncuation(word)
-
-            if word != "" and word is not None:
-                newText.append(word)
-
-        if len(newText) == 0:
-            continue
-
-        tweets_object.tweetsText.append(' '.join(newText))
-        tweets_object.tweetsLabel.append(labels[i])
-    return tweets_object
+from DataRetrival import *
+from Scorer import *
 
 
 def naive_bayes_classifier(tfidf_matrix, labels):
@@ -91,25 +10,21 @@
     return nb_classifier
 
 
-def run():
-    print()
+def run(trainTweets, testTweets):
+    tfidf_featuriser = extract_tfidf_featuriser(trainTweets.tweetsText)
+    train_tfidif_matrix = tfidf_featuriser.transform(trainTweets.tweetsText)
+    test_tfidif_matrix = tfidf_featuriser.transform(testTweets.tweetsText)
+    clf = naive_bayes_classifier(train_tfidif_matrix, trainTweets.tweetsLabel)
+    predictions = clf.predict(test_tfidif_matrix)
+    evaluate_model(clf, testTweets.tweetsText, testTweets.tweetsLabel,predictions)
 
 
-trainTextDir ="Semeval2018-Task2-EmojiPrediction\\Data\\tweet_by_ID_04_2_2021__05_27_42.txt.text"
+trainTextDir = "Semeval2018-Task2-EmojiPrediction\\Data\\tweet_by_ID_04_2_2021__05_27_42.txt.text"
 trainLabelDir = "Semeval2018-Task2-EmojiPrediction\\Data\\tweet_by_ID_04_2_2021__05_27_42.txt.labels"
 testTextDir = "Semeval2018-Task2-EmojiPrediction\\test\\us_test.text"
 testLabelDir = "Semeval2018-Task2-EmojiPrediction\\test\\us_test.labels"
+
 trainTweets = get_train_data(trainTextDir, trainLabelDir)
 testTweets = get_test_data(testTextDir, testLabelDir)
-tfidf_featuriser = extract_tfidf_featuriser(trainTweets.tweetsText)
-train_tfidif_matrix = tfidf_featuriser.transform(trainTweets.tweetsText)
-test_tfidif_matrix = tfidf_featuriser.transform(testTweets.tweetsText)
-clf = naive_bayes_classifier(train_tfidif_matrix, trainTweets.tweetsLabel)
-predictions = clf.predict(test_tfidif_matrix)
-print(predictions)
-print(confusion_matrix(testTweets.tweetsLabel,predictions))
-print("Precision: " + str(precision_score(testTweets.tweetsLabel,predictions,average="macro")))
-print("Recall: " + str(recall_score(testTweets.tweetsLabel,predictions,average="macro")))
-print("F1 Score: " + str(f1_score(testTweets.tweetsLabel,predictions,average="macro")))
-accuracy = np.sum(predictions == testTweets.tweetsLabel)/len(testTweets.tweetsLabel)
-print('Accuracy: {:.3%}'.format(accuracy))
+run(trainTweets,testTweets)
+
Index: .idea/misc.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project version=\"4\">\r\n  <component name=\"JavaScriptSettings\">\r\n    <option name=\"languageLevel\" value=\"ES6\" />\r\n  </component>\r\n  <component name=\"ProjectRootManager\" version=\"2\" project-jdk-name=\"Python 3.7 (NLP3rdYear)\" project-jdk-type=\"Python SDK\" />\r\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/misc.xml b/.idea/misc.xml
--- a/.idea/misc.xml	(revision ab79391eab251b0fefd0d741390dba74ea2ba067)
+++ b/.idea/misc.xml	(date 1613837971064)
@@ -3,5 +3,5 @@
   <component name="JavaScriptSettings">
     <option name="languageLevel" value="ES6" />
   </component>
-  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.7 (NLP3rdYear)" project-jdk-type="Python SDK" />
+  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.7 (NLP3rdYear3-7)" project-jdk-type="Python SDK" />
 </project>
\ No newline at end of file
Index: SVM.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from sklearn.pipeline import make_pipeline\r\nfrom sklearn.preprocessing import StandardScaler\r\nfrom sklearn.svm import SVC\r\nfrom WordEmbeddings import *\r\nfrom Preprocessing import *\r\nfrom Tweets import *\r\nfrom sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score\r\n\r\nimport pickle\r\nimport numpy as np\r\n\r\n\r\ndef check_if_created(filename):\r\n    try:\r\n        file = open(filename + \".pickle\")\r\n        file.close()\r\n        return True\r\n    except IOError:\r\n        print(\"File not found\")\r\n        return False\r\n\r\n\r\ndef get_data(dirText, dirLabel,output_file_name):\r\n    # Obtaining tweet text\r\n    with open(dirText, \"r\",\r\n              encoding=\"utf8\") as t:\r\n        tweets = t.read()\r\n        tweets = tweets.split(\"\\n\")\r\n\r\n    # Obtaining tweet label\r\n    with open(dirLabel, \"r\",\r\n              encoding=\"utf8\") as l:\r\n        labels = l.read()\r\n        labels = labels.split(\"\\n\")\r\n\r\n    tweets_object = preprocess(tweets, labels)\r\n\r\n    with open(output_file_name+'.pickle', 'wb') as handle:\r\n        pickle.dump(tweets_object, handle, protocol=pickle.HIGHEST_PROTOCOL)\r\n\r\n    return tweets_object\r\n\r\n\r\ndef get_train_data(dirTrainText, dirTrainLabel):\r\n    filename = \"TrainTweets\"\r\n    if check_if_created(filename):\r\n        with open(filename + '.pickle', 'rb') as handle:\r\n            return pickle.load(handle)\r\n    else:\r\n        return get_data(dirTrainText, dirTrainLabel,filename)\r\n\r\n\r\ndef get_test_data(dirTestText, dirTestLabel):\r\n    filename = \"TestTweets\"\r\n    if check_if_created(filename):\r\n        with open(filename + '.pickle', 'rb') as handle:\r\n            return pickle.load(handle)\r\n    else:\r\n        return get_data(dirTestText, dirTestLabel, filename)\r\n\r\n\r\ndef preprocess(tweets,labels):\r\n    tweets_object = Tweets()\r\n    for i in range(0, len(tweets)):\r\n        tweets[i] = \" \".join(tweets[i].split())\r\n        tweets[i] = tokenize(tweets[i])\r\n\r\n        newText = []\r\n        for word in tweets[i]:\r\n            # Checking for @ Location and eliminating any words that follow\r\n            if word == \"@\":\r\n                break\r\n\r\n            word = lemmatise(word)\r\n            word = remove_stopwords(word)\r\n            word = remove_url(word)\r\n            word = remove_puncuation(word)\r\n\r\n            if word != \"\" and word is not None:\r\n                newText.append(word)\r\n\r\n        if len(newText) == 0:\r\n            continue\r\n\r\n        tweets_object.tweetsText.append(' '.join(newText))\r\n        tweets_object.tweetsLabel.append(labels[i])\r\n    return tweets_object\r\n\r\n\r\ndef svm(tfidf_matrix, labels):\r\n    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\r\n    clf.fit(tfidf_matrix, labels)\r\n    return clf\r\n\r\n\r\ndef run():\r\n    pass\r\n\r\n\r\ntrainTextDir = \"Semeval2018-Task2-EmojiPrediction\\\\Data\\\\tweet_by_ID_04_2_2021__05_27_42.txt.text\"\r\ntrainLabelDir = \"Semeval2018-Task2-EmojiPrediction\\\\Data\\\\tweet_by_ID_04_2_2021__05_27_42.txt.labels\"\r\ntestTextDir = \"Semeval2018-Task2-EmojiPrediction\\\\test\\\\us_test.text\"\r\ntestLabelDir = \"Semeval2018-Task2-EmojiPrediction\\\\test\\\\us_test.labels\"\r\ntrainTweets = get_train_data(trainTextDir, trainLabelDir)\r\ntestTweets = get_test_data(testTextDir, testLabelDir)\r\ntfidf_featuriser = extract_tfidf_featuriser(trainTweets.tweetsText)\r\ntrain_tfidif_matrix = tfidf_featuriser.transform(trainTweets.tweetsText)\r\ntest_tfidif_matrix = tfidf_featuriser.transform(testTweets.tweetsText)\r\nclf = svm(train_tfidif_matrix, trainTweets.tweetsLabel)\r\npredictions = clf.predict(test_tfidif_matrix)\r\nprint(predictions)\r\nprint(confusion_matrix(testTweets.tweetsLabel,predictions))\r\nprint(\"Precision: \" + str(precision_score(testTweets.tweetsLabel,predictions,average=\"macro\")))\r\nprint(\"Recall: \" + str(recall_score(testTweets.tweetsLabel,predictions,average=\"macro\")))\r\nprint(\"F1 Score: \" + str(f1_score(testTweets.tweetsLabel,predictions,average=\"macro\")))\r\naccuracy = np.sum(predictions == testTweets.tweetsLabel)/len(testTweets.tweetsLabel)\r\nprint('Accuracy: {:.3%}'.format(accuracy))\r\n\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/SVM.py b/SVM.py
--- a/SVM.py	(revision ab79391eab251b0fefd0d741390dba74ea2ba067)
+++ b/SVM.py	(date 1613842986014)
@@ -2,89 +2,8 @@
 from sklearn.preprocessing import StandardScaler
 from sklearn.svm import SVC
 from WordEmbeddings import *
-from Preprocessing import *
-from Tweets import *
-from sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score
-
-import pickle
-import numpy as np
-
-
-def check_if_created(filename):
-    try:
-        file = open(filename + ".pickle")
-        file.close()
-        return True
-    except IOError:
-        print("File not found")
-        return False
-
-
-def get_data(dirText, dirLabel,output_file_name):
-    # Obtaining tweet text
-    with open(dirText, "r",
-              encoding="utf8") as t:
-        tweets = t.read()
-        tweets = tweets.split("\n")
-
-    # Obtaining tweet label
-    with open(dirLabel, "r",
-              encoding="utf8") as l:
-        labels = l.read()
-        labels = labels.split("\n")
-
-    tweets_object = preprocess(tweets, labels)
-
-    with open(output_file_name+'.pickle', 'wb') as handle:
-        pickle.dump(tweets_object, handle, protocol=pickle.HIGHEST_PROTOCOL)
-
-    return tweets_object
-
-
-def get_train_data(dirTrainText, dirTrainLabel):
-    filename = "TrainTweets"
-    if check_if_created(filename):
-        with open(filename + '.pickle', 'rb') as handle:
-            return pickle.load(handle)
-    else:
-        return get_data(dirTrainText, dirTrainLabel,filename)
-
-
-def get_test_data(dirTestText, dirTestLabel):
-    filename = "TestTweets"
-    if check_if_created(filename):
-        with open(filename + '.pickle', 'rb') as handle:
-            return pickle.load(handle)
-    else:
-        return get_data(dirTestText, dirTestLabel, filename)
-
-
-def preprocess(tweets,labels):
-    tweets_object = Tweets()
-    for i in range(0, len(tweets)):
-        tweets[i] = " ".join(tweets[i].split())
-        tweets[i] = tokenize(tweets[i])
-
-        newText = []
-        for word in tweets[i]:
-            # Checking for @ Location and eliminating any words that follow
-            if word == "@":
-                break
-
-            word = lemmatise(word)
-            word = remove_stopwords(word)
-            word = remove_url(word)
-            word = remove_puncuation(word)
-
-            if word != "" and word is not None:
-                newText.append(word)
-
-        if len(newText) == 0:
-            continue
-
-        tweets_object.tweetsText.append(' '.join(newText))
-        tweets_object.tweetsLabel.append(labels[i])
-    return tweets_object
+from Scorer import *
+from DataRetrival import *
 
 
 def svm(tfidf_matrix, labels):
@@ -93,8 +12,13 @@
     return clf
 
 
-def run():
-    pass
+def run(trainTweets,testTweets):
+    tfidf_featuriser = extract_tfidf_featuriser(trainTweets.tweetsText)
+    train_tfidif_matrix = tfidf_featuriser.transform(trainTweets.tweetsText)
+    test_tfidif_matrix = tfidf_featuriser.transform(testTweets.tweetsText)
+    clf = svm(train_tfidif_matrix, trainTweets.tweetsLabel)
+    predictions = clf.predict(test_tfidif_matrix)
+    evaluate_model(testTweets.tweetsLabel,predictions)
 
 
 trainTextDir = "Semeval2018-Task2-EmojiPrediction\\Data\\tweet_by_ID_04_2_2021__05_27_42.txt.text"
@@ -103,16 +27,5 @@
 testLabelDir = "Semeval2018-Task2-EmojiPrediction\\test\\us_test.labels"
 trainTweets = get_train_data(trainTextDir, trainLabelDir)
 testTweets = get_test_data(testTextDir, testLabelDir)
-tfidf_featuriser = extract_tfidf_featuriser(trainTweets.tweetsText)
-train_tfidif_matrix = tfidf_featuriser.transform(trainTweets.tweetsText)
-test_tfidif_matrix = tfidf_featuriser.transform(testTweets.tweetsText)
-clf = svm(train_tfidif_matrix, trainTweets.tweetsLabel)
-predictions = clf.predict(test_tfidif_matrix)
-print(predictions)
-print(confusion_matrix(testTweets.tweetsLabel,predictions))
-print("Precision: " + str(precision_score(testTweets.tweetsLabel,predictions,average="macro")))
-print("Recall: " + str(recall_score(testTweets.tweetsLabel,predictions,average="macro")))
-print("F1 Score: " + str(f1_score(testTweets.tweetsLabel,predictions,average="macro")))
-accuracy = np.sum(predictions == testTweets.tweetsLabel)/len(testTweets.tweetsLabel)
-print('Accuracy: {:.3%}'.format(accuracy))
 
+run(trainTweets,testTweets)
Index: Scorer.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Scorer.py b/Scorer.py
new file mode 100644
--- /dev/null	(date 1613846273507)
+++ b/Scorer.py	(date 1613846273507)
@@ -0,0 +1,35 @@
+import numpy as np
+from sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score,plot_confusion_matrix
+import matplotlib.pyplot as plt
+
+
+def get_class_names():
+    output_classes = []
+    with open("Semeval2018-Task2-EmojiPrediction\\mapping\\us_mapping.txt", "r",encoding="utf8") as l:
+        classes = l.read()
+        classes = classes.split("\n")
+        for className in classes:
+            classText = className.split("\t")
+            output_classes.append(''.join(classText[1:]))
+
+    return output_classes
+
+
+def evaluate_model(model, test_text, true_labels, predicted_labels):
+    print(confusion_matrix(true_labels, predicted_labels))
+    print("Precision: " + str(precision_score(true_labels, predicted_labels,average="micro")))
+    print("Recall: " + str(recall_score(true_labels, predicted_labels,average="micro")))
+    print("F1 Score: " + str(f1_score(true_labels, predicted_labels,average="micro")))
+    accuracy = np.sum(predicted_labels == true_labels)/len(true_labels)
+    print('Accuracy: {:.3%}'.format(accuracy))
+    confusion_matrixActual = confusion_matrix(true_labels, predicted_labels)
+    FP = confusion_matrixActual.sum(axis=0) - np.diag(confusion_matrixActual)
+    FN = confusion_matrixActual.sum(axis=0) - np.diag(confusion_matrixActual)
+    TP = np.diag(confusion_matrixActual)
+    print("FP", confusion_matrixActual.sum(axis=0) - np.diag(confusion_matrixActual))
+    print("FN",confusion_matrixActual.sum(axis=1) - np.diag(confusion_matrixActual))
+    print("TP",np.diag(confusion_matrixActual))
+    print("TN",confusion_matrixActual.values.sum() - (FP + FN + TP))
+    #plotCM = plot_confusion_matrix(model,test_text, true_labels, display_labels=get_class_names(),cmap=plt.cm.Blues)
+    #plotCM.ax_.set_title("")
+    #plt.show()
\ No newline at end of file
Index: DataRetrival.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/DataRetrival.py b/DataRetrival.py
new file mode 100644
--- /dev/null	(date 1613839420828)
+++ b/DataRetrival.py	(date 1613839420828)
@@ -0,0 +1,79 @@
+from Preprocessing import *
+from Tweets import *
+import pickle
+
+def check_if_created(filename):
+    try:
+        file = open(filename + ".pickle")
+        file.close()
+        return True
+    except IOError:
+        print("File not found")
+        return False
+
+
+def get_data(dirText, dirLabel,output_file_name):
+    # Obtaining tweet text
+    with open(dirText, "r",
+              encoding="utf8") as t:
+        tweets = t.read()
+        tweets = tweets.split("\n")
+
+    # Obtaining tweet label
+    with open(dirLabel, "r",
+              encoding="utf8") as l:
+        labels = l.read()
+        labels = labels.split("\n")
+
+    tweets_object = preprocess(tweets, labels)
+
+    with open(output_file_name+'.pickle', 'wb') as handle:
+        pickle.dump(tweets_object, handle, protocol=pickle.HIGHEST_PROTOCOL)
+
+    return tweets_object
+
+
+def get_train_data(dirTrainText, dirTrainLabel):
+    filename = "TrainTweets"
+    if check_if_created(filename):
+        with open(filename + '.pickle', 'rb') as handle:
+            return pickle.load(handle)
+    else:
+        return get_data(dirTrainText, dirTrainLabel,filename)
+
+
+def get_test_data(dirTestText, dirTestLabel):
+    filename = "TestTweets"
+    if check_if_created(filename):
+        with open(filename + '.pickle', 'rb') as handle:
+            return pickle.load(handle)
+    else:
+        return get_data(dirTestText, dirTestLabel, filename)
+
+
+def preprocess(tweets,labels):
+    tweets_object = Tweets()
+    for i in range(0, len(tweets)):
+        tweets[i] = " ".join(tweets[i].split())
+        tweets[i] = tokenize(tweets[i])
+
+        newText = []
+        for word in tweets[i]:
+            # Checking for @ Location and eliminating any words that follow
+            if word == "@":
+                break
+
+            word = lemmatise(word)
+            word = remove_stopwords(word)
+            word = remove_url(word)
+            word = remove_puncuation(word)
+
+            if word != "" and word is not None:
+                newText.append(word)
+
+        if len(newText) == 0:
+            continue
+
+        tweets_object.tweetsText.append(' '.join(newText))
+        tweets_object.tweetsLabel.append(labels[i])
+    return tweets_object
\ No newline at end of file
Index: SmallTester.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/SmallTester.py b/SmallTester.py
new file mode 100644
--- /dev/null	(date 1613844733744)
+++ b/SmallTester.py	(date 1613844733744)
@@ -0,0 +1,35 @@
+from sklearn.pipeline import make_pipeline
+from sklearn.preprocessing import StandardScaler
+from sklearn.svm import SVC
+from WordEmbeddings import *
+from Scorer import *
+from DataRetrival import *
+
+
+def svm(tfidf_matrix, labels):
+    clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))
+    clf.fit(tfidf_matrix, labels)
+    return clf
+
+
+def run(trainTweets,testTweets):
+    tfidf_featuriser = extract_tfidf_featuriser(trainTweets.tweetsText)
+    train_tfidif_matrix = tfidf_featuriser.transform(trainTweets.tweetsText)
+    test_tfidif_matrix = tfidf_featuriser.transform(testTweets.tweetsText)
+    clf = svm(train_tfidif_matrix, trainTweets.tweetsLabel)
+    predictions = clf.predict(test_tfidif_matrix)
+    evaluate_model(clf,testTweets.tweetsText,testTweets.tweetsLabel,predictions)
+
+
+trainTextDir = "Semeval2018-Task2-EmojiPrediction\\Data\\tweet_by_ID_04_2_2021__05_27_42.txt.text"
+trainLabelDir = "Semeval2018-Task2-EmojiPrediction\\Data\\tweet_by_ID_04_2_2021__05_27_42.txt.labels"
+testTextDir = "Semeval2018-Task2-EmojiPrediction\\test\\us_test.text"
+testLabelDir = "Semeval2018-Task2-EmojiPrediction\\test\\us_test.labels"
+trainTweets = get_train_data(trainTextDir, trainLabelDir)
+testTweets = get_test_data(testTextDir, testLabelDir)
+
+
+trainTweets.tweetsText = trainTweets.tweetsText[:1000]
+trainTweets.tweetsLabel = trainTweets.tweetsLabel[:1000]
+
+run(trainTweets,testTweets)
Index: RandomForest.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/RandomForest.py b/RandomForest.py
new file mode 100644
--- /dev/null	(date 1613844990010)
+++ b/RandomForest.py	(date 1613844990010)
@@ -0,0 +1,31 @@
+from sklearn.pipeline import make_pipeline
+from sklearn.preprocessing import StandardScaler
+from sklearn.ensemble import RandomForestClassifier
+from WordEmbeddings import *
+from Scorer import *
+from DataRetrival import *
+
+
+def random_forest(tfidf_matrix, labels):
+    rf_classifier = RandomForestClassifier()
+    rf_classifier.fit(tfidf_matrix, labels)
+    return rf_classifier
+
+
+def run(trainTweets,testTweets):
+    tfidf_featuriser = extract_tfidf_featuriser(trainTweets.tweetsText)
+    train_tfidif_matrix = tfidf_featuriser.transform(trainTweets.tweetsText)
+    test_tfidif_matrix = tfidf_featuriser.transform(testTweets.tweetsText)
+    clf = random_forest(train_tfidif_matrix, trainTweets.tweetsLabel)
+    predictions = clf.predict(test_tfidif_matrix)
+    evaluate_model(clf, testTweets.tweetsText, testTweets.tweetsLabel, predictions)
+
+
+trainTextDir = "Semeval2018-Task2-EmojiPrediction\\Data\\tweet_by_ID_04_2_2021__05_27_42.txt.text"
+trainLabelDir = "Semeval2018-Task2-EmojiPrediction\\Data\\tweet_by_ID_04_2_2021__05_27_42.txt.labels"
+testTextDir = "Semeval2018-Task2-EmojiPrediction\\test\\us_test.text"
+testLabelDir = "Semeval2018-Task2-EmojiPrediction\\test\\us_test.labels"
+trainTweets = get_train_data(trainTextDir, trainLabelDir)
+testTweets = get_test_data(testTextDir, testLabelDir)
+
+run(trainTweets, testTweets)
